9.2: C. Jiang, D. Ojika, B. Patel and H. Lam, "Optimized FPGA-based Deep Learning Accelerator for Sparse CNN using High Bandwidth Memory," 2021 IEEE 29th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), 2021, pp. 157-164.
9.3: (review needed for SVD)Denil, Misha, Shakibi, Babak, Dinh, Laurent, de Freitas, Nando, et al. Predicting parameters in deep learning. In Advances in Neural Information Processing Systems, pp. 2148–2156, 2013.
9.4: Vanhoucke, Vincent, Senior, Andrew, and Mao, Mark Z. Improving the speed of neural networks on cpus. In Proc. Deep Learning and Unsupervised Feature Learning NIPS Workshop, 2011.
9.5：Han, Song, Pool, Jeff, Tran, John, and Dally, William J. Learning both weights and connections for efficient neural networks. In Advances in Neural Information Processing Systems, 2015
9.6：J. Wang et al., "High PE Utilization CNN Accelerator with Channel Fusion Supporting Pattern-Compressed Sparse Neural Networks," 2020 57th ACM/IEEE Design Automation Conference (DAC), 2020, pp. 1-6
9.7：Mao, H., Han, S., Pool, J., Li, W., Liu, X., Wang, Y., & Dally, W. J. (2017). Exploring the Granularity of Sparsity in Convolutional Neural Networks. 2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW).
9.8：Lu, L., Xie, J., Huang, R., Zhang, J., Lin, W., & Liang, Y. (2019). An Efficient Hardware Accelerator for Sparse Convolutional Neural Networks on FPGAs. 2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)
9.9：Zhu, C., Huang, K., Yang, S., Zhu, Z., Zhang, H., & Shen, H. (2020). An Efficient Hardware Accelerator for Structured Sparse Convolutional Neural Networks on FPGAs. IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 1–13.
9.10: Lu, L., & Liang, Y. SpWA: An Efficient Sparse Winograd Convolutional Neural Networks Accelerator on FPGAs, 2018 DAC.
9.15：S. Huang, C. Pearson, R. Nagi, J. Xiong, D. Chen and W. Hwu, "Accelerating Sparse Deep Neural Networks on FPGAs," 2019 IEEE High Performance Extreme Computing Conference (HPEC), 2019.
9.16:C. Deng, Y. Sui, S. Liao, X. Qian and B. Yuan, "GoSPA: An Energy-efficient High-performance Globally Optimized SParse Convolutional Neural Network Accelerator," 2021 ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA), 2021.
9.17：L. Lu, Y. Liang, Q. Xiao and S. Yan, "Evaluating Fast Algorithms for Convolutional Neural Networks on FPGAs," 2017 IEEE 25th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), 2017, pp. 101-108, doi: 10.1109/FCCM.2017.64.
9.22: Parashar, A., Rhu, M., Mukkara, A., Puglielli, A., Venkatesan, R., Khailany, B., … Dally, W. J. SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks. ISCA 2017.
9.23: Gondimalla, A., Chesnut, N., Thottethodi, M., & Vijaykumar, T. N. (2019). SparTen: A Sparse Tensor Accelerator for Convolutional Neural Networks. MICRO 2019.
9.24: J. -F. Zhang, C. -E. Lee, C. Liu, Y. S. Shao, S. W. Keckler and Z. Zhang, "SNAP: An Efficient Sparse Neural Acceleration Processor for Unstructured Sparse Deep Neural Network Inference," in IEEE Journal of Solid-State Circuits.
9.25: H. Jun et al., "HBM (High Bandwidth Memory) DRAM Technology and Architecture," 2017 IEEE International Memory Workshop (IMW), 2017.
